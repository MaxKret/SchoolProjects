# -*- coding: utf-8 -*-
"""clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14e-BHRIEMSIZL1iyNRkycGX320B7eedQ

# Clustering Lab

## Group: &lt; Lab Group Number here &gt;

### Members: &lt; Members of the group here &gt; 

Grouping data into other data that is similar to it is sometimes very helpful in defining categories on data, and adding structure to a visuzliation. 

We'll look at several examples of using libraries to cluster data using
  - k-means
  - dbscan, and
  - hierarchical clustering

## Our data

There are 234 exoplanets listed by [NASA](https://exoplanets.nasa.gov/discovery/exoplanet-catalog/) that orbit stars that are visible to the naked eye (as of DL time April 2021). Let's use this data to form clusters!
"""

import pandas as pd
import numpy as np
import altair as alt

# For k-means and dbscan
from sklearn.datasets import make_blobs
from sklearn.datasets import make_moons
from sklearn.cluster import KMeans
from sklearn.cluster import DBSCAN

# This is for our hierarchical clustering
from scipy.cluster.hierarchy import dendrogram, linkage

import matplotlib.pyplot as plt

# This data is actually tab seperated, so I'll pass in a delimter argument. 
df = pd.read_csv('https://gist.githubusercontent.com/TieJean/1d7f7b21fd0220e365c89145eecb0571/raw/fcf54bf8966223f4b8227f07a287d832e6ef39b1/exoplanets.csv', delimiter='\t')

# We use `head` and `tail` quite a bit, let's look at another with to get some data with `sample` 
# sample will randomly pull the argument number of rows from the dataframe.
df.sample(35)

"""## Data Engineering!

As some of you are discovering in your final projects, data engineering can be difficult process. 
In this data set, we don't have to worry about merging and joining, but our clustering algorithms
take in numerical data.  Let's check our columns and see what type of data we have:
"""

df.dtypes

"""... That 'object' for Planet Mass is a problem!! We can see that it has units encoded in it, "Jupiters" or "Earths"

Lets count how many Earths and how many Jupiters there are:
"""

df['PLANET MASS'].str.match(r'(.*Earths$)').sum()

"""and now Jupiters"""

df['PLANET MASS'].str.match(r'(.*Jupiters$)').sum()

"""A quick check, and we find that these two units cover all the rows in the dataframe.  Now, how do we strip the
units off and normalize the column so that they are all in the same units?  

Let's first store the index that has the earth units 
"""

earth_index = df['PLANET MASS'].str.match(r'(.*Earths$)')
earth_index

"""We can now use this to filter out the earth units in the whole dataframe like so:"""

df[earth_index]

"""Now, let's strip out the letters from the planet mass column, while printing out some before and afters
so we can check our work
"""

df.tail()

df['PLANET MASS'].replace('[A-Z][a-z]+','',regex=True, inplace = True)
df.tail()

df[earth_index].head()

"""Now, we have to convert from the `object` type to the `float64` in the planet mass column"""

df['PLANET MASS'] = pd.to_numeric(df['PLANET MASS'])

# Check it!
df.dtypes

"""The earth units now need to be converted to Jupiters. Some googling tells me that

  - Earth is 5.972 × 10^24 kg
  - Jupiter is 1.898 × 10^27 kg

So how many earths in one jupiter?
"""

(1.898 * 10**27)/(5.972 * 10**24)

"""To convert earths to jupiters, we divide all of the Earth units by the above number"""

df.loc[earth_index,'PLANET MASS'] = df.loc[earth_index,'PLANET MASS']/317.816

"""Now, let's look at LIGHT-YEARS FROM EARTH as a function of PLANET MASS"""

alt.Chart(df).mark_circle().encode(
    x='PLANET MASS:Q',
    y='LIGHT-YEARS FROM EARTH:Q'
)

"""This looks very bunched up in mass!  Why don't we try ploting the LIGHT-YEARS FROM EARTH as a function of the log of the PLANET MASS instead?"""

alt.Chart(df).mark_circle().encode(
    x=alt.X('PLANET MASS:Q',scale=alt.Scale(type="log")),
    y='LIGHT-YEARS FROM EARTH:Q'
)

"""hmmm ... how about a log log plot? (where both axes are on a log scale)"""

alt.Chart(df).mark_circle().encode(
    x=alt.X('PLANET MASS:Q',scale=alt.Scale(type="log")),
    y=alt.Y('LIGHT-YEARS FROM EARTH:Q',scale=alt.Scale(type="log"))
)

"""## The clustering algorthms

Now, lets look at the scikit-learn libraries and learn how to use them to cluster. 

### K-Means

First step is to generate some toy data, and we'll use a built in random blob generator:
"""

X, y = make_blobs(n_samples=100,
                  n_features=2,
                  centers=3,
                  cluster_std=1,
                  center_box=(-10.0, 10.0),
                  shuffle=True,
                  random_state=23)

df_toy = pd.DataFrame()
df_toy['x'] = X[:,0]
df_toy['y'] = X[:,1]
df_toy['cluster'] = y

alt.Chart(df_toy).mark_circle().encode(
    x='x',
    y='y',
    color='cluster:N'
)

"""What happens if we try to cluster the data with $k=2$?"""

# Creates the object that will perform k-means with k=2
clusterer = KMeans(n_clusters=2, random_state=10)

# fit_predict will assign cluster labels to the data passed in as a parameter
df_toy['new_cluster_labels'] = clusterer.fit_predict(X)

alt.Chart(df_toy).mark_circle().encode(
    x='x',
    y='y',
    color='new_cluster_labels:N'
)

# inspect df_toy for fun
df_toy.sample(10)

"""### DBScan

K-means works well on blob data, but sometimes we want to consider clusters that are continuously dense, and not necessarily blobs. 

There is another built-in random number generator that will make us `C`'s (or cresent moons)
"""

X, y = make_moons(200, noise=.05, random_state=23)
df_toy = pd.DataFrame()
df_toy['x'] = X[:,0]
df_toy['y'] = X[:,1]
df_toy['cluster'] = y

alt.Chart(df_toy).mark_circle().encode(
    x='x',
    y='y',
    color='cluster:N'
)

# Creates the object and fit the data in the same call.  The params eps and min_samples are hyperparameters
db = DBSCAN(eps=0.5, min_samples=10).fit(X)

df_toy['new_cluster_labels'] = db.labels_

alt.Chart(df_toy).mark_circle().encode(
    x='x',
    y='y',
    color='new_cluster_labels:N'
)

"""What happened?  The values eps and min_samples are hyper parameters that define the density.  Lets' try with a different set of hyperparameters:"""

# Creates the object and fit the data in the same call.  The params eps and min_samples are hyperparameters
db = DBSCAN(eps=0.3, min_samples=10).fit(X)

df_toy['new_cluster_labels'] = db.labels_

alt.Chart(df_toy).mark_circle().encode(
    x='x',
    y='y',
    color='new_cluster_labels:N'
)

"""Much better!  Now, the cluster label matches what we expected from generating the data!

### Hierarchical Clustering 

To demonstrate hierarchical clustering, we'll use the voting records of the US states in presidential elections. 
This is data from _before_ our last election.
"""

# Load the data, save off the state names into another series and just leave the attributes.
df_X = pd.read_csv('https://gist.githubusercontent.com/TieJean/a4acaad907d1dcec6497e049fb2d3857/raw/d0144e9092547a627d5b746725cbdb73f1558159/republican_percentage_by_state.csv')
s_states = df_X['State']
df_X = df_X.drop(columns=['State'])

# Plot the dendrogram for the Ward proximity measure
Z = linkage(df_X, 'ward')
fig = plt.figure(figsize=(25, 8))
dn = dendrogram(Z, labels=list(s_states), leaf_font_size=14)
plt.title("Dendrogram on the Voting Dataset", fontsize=22)
plt.xlabel("State", size=20)
plt.ylabel("Height", size=20)
plt.show()

"""Note that Arizona and Georgia are in the same cluster! Isn't that interesting? So are Michagan and Wisconsin.  The coloring is inherited from the dendrogram library in SciPy which uses matplotlib.

## Your Turn!

Using the planets data set, using the same two attributes as above (LIGHT-YEARS FROM EARTH and PLANET MASS).  

  1. Find an optimal k-means clustering and plot the results in log-log space.
  2. Find an optimal DBSCAN clustering and plot the results in log-log space. Note that $-1$ is the cluster label for noise.
  3. In a markdown cell describe which algorithm you think is a better fit for this data and why. 
  
This lab you might need to do a little more data massaging to make things work out! Don't drop a row if it has valid data for the two columns that you are intrested in. Clusters should be made in log-log space, and the guides on the graph should indicate the data is in log-log space. 

Hint: You can transform the data to be clustered as a preprocessing step, using `df[col].apply(np.log)`, but remember to preserve the original values for plotting the cluster results. Encode cluster membership as a color as in the examples above.
"""

df.dropna(inplace=True, subset=['PLANET MASS', 'LIGHT-YEARS FROM EARTH'])

# 1
clusterer = KMeans(n_clusters=3, random_state=None)
df['new_cluster_labels'] = clusterer.fit_predict(df[['PLANET MASS', 'LIGHT-YEARS FROM EARTH']])

alt.Chart(df).mark_circle().encode(
    x=alt.X('PLANET MASS:Q',scale=alt.Scale(type="log")),
    y=alt.Y('LIGHT-YEARS FROM EARTH:Q',scale=alt.Scale(type="log")),
    color='new_cluster_labels:N'
)

four_classes = lambda eps,min_s: len(np.unique(DBSCAN(eps=eps, min_samples=min_s).fit(df[['PLANET MASS', 'LIGHT-YEARS FROM EARTH']]).labels_)) == 4
indices = []
for i in range(1,201,1):
  for j in range(1,101,1):
    if four_classes(i,j):
      indices.append((i,j))

# 2 
# 39 4, 38 4, 
eps,min_s = indices[0]
df['new_cluster_labels'] = DBSCAN(eps=eps, min_samples=min_s).fit(df[['PLANET MASS', 'LIGHT-YEARS FROM EARTH']]).labels_

alt.Chart(df).mark_circle().encode(
    x=alt.X('PLANET MASS:Q',scale=alt.Scale(type="log")),
    y=alt.Y('LIGHT-YEARS FROM EARTH:Q',scale=alt.Scale(type="log")),
    color='new_cluster_labels:N'
)

my_eps = 15
df['new_cluster_labels1'] = DBSCAN(eps=my_eps, min_samples=5).fit(df[['PLANET MASS', 'LIGHT-YEARS FROM EARTH']]).labels_
df['new_cluster_labels2'] = DBSCAN(eps=my_eps, min_samples=6).fit(df[['PLANET MASS', 'LIGHT-YEARS FROM EARTH']]).labels_
df['new_cluster_labels3'] = DBSCAN(eps=my_eps, min_samples=7).fit(df[['PLANET MASS', 'LIGHT-YEARS FROM EARTH']]).labels_

base = alt.Chart(df).mark_circle().encode(
    x=alt.X('PLANET MASS:Q',scale=alt.Scale(type="log")),
    y=alt.Y('LIGHT-YEARS FROM EARTH:Q',scale=alt.Scale(type="log")),
)

base.encode(color='new_cluster_labels1:N')

base.encode(color='new_cluster_labels2:N')

base.encode(color='new_cluster_labels3:N')



"""### 3 

➡️ Your words here ⬅️
"""

